COMPREHENSIVE CODE EXPLANATION: STEERING ACCURACY ML MODEL
================================================================

This document provides detailed explanations for each code block in the steering_accuracy_ml.py file.
The program creates a machine learning model for predicting steering corrections in micro tunneling operations.

TABLE OF CONTENTS
=================
1. Imports & Setup
2. Class Initialization
3. Data Loading Method
4. Feature Engineering Method
5. Target Creation Method
6. ML Data Preparation Method
7. Model Training Method
8. Prediction and Utility Methods
9. Main Execution Flow
10. Summary & Key Learning Points

================================================================

1. IMPORTS & SETUP (Lines 1-17)
===============================

Code Block:
-----------
#!/usr/bin/env python3
"""
AVN1200 Microtunnelling Steering Accuracy ML Model
Predicts steering corrections and deviation trends for improved tunnel alignment
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Tuple, Dict, Any
import warnings
warnings.filterwarnings('ignore')

Purpose:
--------
Sets up all required libraries for the ML pipeline

Detailed Breakdown:
------------------
- pandas: Data manipulation and CSV reading
- numpy: Mathematical operations and array handling
- sklearn.model_selection.train_test_split: Splits data into training/testing sets
- sklearn.ensemble.RandomForestRegressor: Main ML algorithm (ensemble of decision trees)
- sklearn.preprocessing.StandardScaler: Normalizes features to same scale
- sklearn.metrics: Evaluation metrics (R², MAE, RMSE)
- matplotlib.pyplot + seaborn: Data visualization
- typing: Type hints for better code documentation
- warnings.filterwarnings('ignore'): Suppresses warning messages

================================================================

2. CLASS INITIALIZATION (Lines 19-28)
=====================================

Code Block:
-----------
class SteeringAccuracyPredictor:
    """
    Machine Learning model for predicting steering corrections in microtunnelling
    """
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.feature_columns = []
        self.target_columns = []

Purpose:
--------
Creates the main class that encapsulates the entire ML pipeline

Detailed Breakdown:
------------------
- self.model = None: Placeholder for the trained ML model (initially empty)
- self.scaler = StandardScaler(): Feature scaling object (normalizes data to prevent bias toward large numbers)
- self.feature_columns = []: Will store names of input features for consistency
- self.target_columns = []: Will store names of output predictions

Why This Design:
---------------
- Object-oriented approach keeps all methods and data together
- State variables maintain consistency between training and prediction
- Scaler remembers scaling parameters from training data

================================================================

3. DATA LOADING METHOD (Lines 30-47)
====================================

Code Block:
-----------
def load_data(self, csv_path: str) -> pd.DataFrame:
    """Load and preprocess AVN1200 drive data"""
    # Column mapping based on your protocol
    columns = [
        'date', 'time', 'tunnel_length', 'hor_dev_machine', 'vert_dev_machine',
        'hor_dev_drill_head', 'vert_dev_drill_head', 'yaw', 'pitch', 'roll',
        'temperature', 'survey_mode', 'sc_cyl_01', 'sc_cyl_02', 'sc_cyl_03',
        'sc_cyl_04', 'advance_speed', 'interjack_force', 'interjack_active',
        'working_pressure', 'revolution_rpm', 'earth_pressure', 'total_force'
    ]
    
    df = pd.read_csv(csv_path, names=columns, skiprows=1)
    
    # Convert date/time
    df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])
    df = df.sort_values('datetime').reset_index(drop=True)
    
    return df

Purpose:
--------
Reads raw CSV data from tunneling machine and structures it for analysis

Detailed Column Breakdown:
-------------------------

Position & Orientation:
- hor_dev_machine/vert_dev_machine: How far off-target the machine body is (mm)
- hor_dev_drill_head/vert_dev_drill_head: How far off-target the cutting head is (mm)
- yaw, pitch, roll: Machine orientation angles (degrees)
- tunnel_length: Current distance tunneled (meters)

Steering Controls:
- sc_cyl_01/02/03/04: Stroke position of 4 steering cylinders (mm) - these physically steer the machine

Machine Performance:
- advance_speed: Forward tunneling speed (mm/min)
- revolution_rpm: Cutting head rotation speed
- total_force: Total driving force applied

Ground Conditions:
- earth_pressure: Soil resistance pressure
- working_pressure: Hydraulic system pressure
- interjack_force: Force from pushing segments
- temperature: Ambient temperature

Data Processing Steps:
---------------------
1. names=columns: Assigns meaningful names to CSV columns
2. skiprows=1: Skips header row
3. pd.to_datetime(): Combines date/time into single timestamp
4. sort_values('datetime'): Orders data chronologically
5. reset_index(drop=True): Renumbers rows 0,1,2...

================================================================

4. FEATURE ENGINEERING METHOD (Lines 49-92)
===========================================

This is the most complex method. Breaking it into sections:

Section 1: Deviation Metrics (Lines 52-55)
------------------------------------------
Code:
df['total_deviation_machine'] = np.sqrt(df['hor_dev_machine']**2 + df['vert_dev_machine']**2)
df['total_deviation_drill_head'] = np.sqrt(df['hor_dev_drill_head']**2 + df['vert_dev_drill_head']**2)
df['deviation_difference'] = df['total_deviation_drill_head'] - df['total_deviation_machine']

Purpose: Creates comprehensive deviation measurements

Detailed Breakdown:
- total_deviation_machine: Pythagorean theorem to get overall distance from target (√(horizontal² + vertical²))
- total_deviation_drill_head: Same calculation for cutting head position
- deviation_difference: Shows if drill head is ahead/behind machine body alignment

Engineering Insight: Total deviation is more meaningful than separate horizontal/vertical values for steering decisions.

Section 2: Steering Effort Indicators (Lines 57-60)
---------------------------------------------------
Code:
df['steering_cylinder_range'] = df[['sc_cyl_01', 'sc_cyl_02', 'sc_cyl_03', 'sc_cyl_04']].max(axis=1) - \
                               df[['sc_cyl_01', 'sc_cyl_02', 'sc_cyl_03', 'sc_cyl_04']].min(axis=1)
df['avg_cylinder_stroke'] = df[['sc_cyl_01', 'sc_cyl_02', 'sc_cyl_03', 'sc_cyl_04']].mean(axis=1)

Purpose: Quantifies how hard the steering system is working

Detailed Breakdown:
- steering_cylinder_range: Difference between most extended and most retracted cylinder
- avg_cylinder_stroke: Average position of all 4 cylinders

Engineering Insight:
- Large range = aggressive steering correction happening
- High average = steering bias in one direction

Section 3: Ground Resistance Features (Lines 62-65)
---------------------------------------------------
Code:
df['pressure_ratio'] = df['earth_pressure'] / (df['working_pressure'] + 0.1)  # Avoid division by zero
df['force_per_advance'] = df['total_force'] / (df['advance_speed'] + 0.1)
df['steering_resistance'] = df['total_force'] / (df['steering_cylinder_range'] + 1)

Purpose: Measures how difficult the ground conditions are

Detailed Breakdown:
- pressure_ratio: Earth resistance vs hydraulic power (higher = harder ground)
- force_per_advance: Force needed per unit of forward progress (efficiency metric)
- steering_resistance: How much force is needed to achieve steering corrections
- + 0.1 and + 1: Prevents division by zero errors

Engineering Insight: These ratios normalize raw measurements and reveal ground condition patterns.

Section 4: Alignment Trend Features (Lines 67-75)
-------------------------------------------------
Code:
window_size = 5
df['hor_dev_trend'] = df['hor_dev_machine'].rolling(window=window_size, min_periods=1).apply(
    lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0
)
df['vert_dev_trend'] = df['vert_dev_machine'].rolling(window=window_size, min_periods=1).apply(
    lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) > 1 else 0
)
df['deviation_trend_magnitude'] = np.sqrt(df['hor_dev_trend']**2 + df['vert_dev_trend']**2)

Purpose: Detects if deviation is getting worse or better over time

Detailed Breakdown:
- rolling(window=window_size): Looks at last 5 readings
- np.polyfit(range(len(x)), x, 1)[0]: Fits linear trend line, returns slope
- Positive slope = deviation increasing (bad)
- Negative slope = deviation decreasing (good)
- deviation_trend_magnitude: Overall rate of change regardless of direction

Engineering Insight: Trend is often more important than current position - allows predictive steering.

Section 5: Moving Averages (Lines 77-80)
----------------------------------------
Code:
df['advance_speed_ma'] = df['advance_speed'].rolling(window=3, min_periods=1).mean()
df['total_force_ma'] = df['total_force'].rolling(window=3, min_periods=1).mean()
df['earth_pressure_ma'] = df['earth_pressure'].rolling(window=3, min_periods=1).mean()

Purpose: Smooths out noisy sensor readings

Detailed Breakdown:
- rolling(window=3).mean(): Average of last 3 readings
- Reduces impact of sensor spikes/noise
- Provides more stable input for ML model

Section 6: Time-Based Features (Lines 82-85)
--------------------------------------------
Code:
df['time_diff'] = df['datetime'].diff().dt.total_seconds() / 3600  # Hours
df['progress_rate'] = df['tunnel_length'].diff() / df['time_diff']  # m/hour
df['hour_of_day'] = df['datetime'].dt.hour

Purpose: Captures temporal patterns in tunneling performance

Detailed Breakdown:
- time_diff: Hours between readings
- progress_rate: Tunneling speed in meters/hour
- hour_of_day: Time of day (0-23) - operator fatigue patterns

Section 7: Lag Features (Lines 87-91)
-------------------------------------
Code:
for col in ['sc_cyl_01', 'sc_cyl_02', 'sc_cyl_03', 'sc_cyl_04']:
    df[f'{col}_prev'] = df[col].shift(1)
    df[f'{col}_change'] = df[col] - df[f'{col}_prev']

Purpose: Learns from previous steering actions and their effects

Detailed Breakdown:
- shift(1): Gets previous reading value
- _change: How much each cylinder moved since last reading
- Allows model to learn "if I moved cylinder 1 by X, what happened?"

Engineering Insight: Steering effects have delayed response - this captures the cause-effect relationship.

================================================================

5. TARGET CREATION METHOD (Lines 94-109)
========================================

Code Block:
-----------
def create_targets(self, df: pd.DataFrame) -> pd.DataFrame:
    """Create target variables for steering prediction"""
    
    # 1. NEXT DEVIATION (What we want to predict)
    df['next_hor_deviation'] = df['hor_dev_machine'].shift(-1)
    df['next_vert_deviation'] = df['vert_dev_machine'].shift(-1)
    df['next_total_deviation'] = df['total_deviation_machine'].shift(-1)
    
    # 2. REQUIRED STEERING CORRECTION (Based on next deviation)
    df['required_hor_correction'] = df['next_hor_deviation'] - df['hor_dev_machine']
    df['required_vert_correction'] = df['next_vert_deviation'] - df['vert_dev_machine']
    
    # 3. DEVIATION IMPROVEMENT (Is steering getting better?)
    df['deviation_improvement'] = df['total_deviation_machine'] - df['next_total_deviation']
    
    return df

Purpose:
--------
Creates the "answers" that the ML model will learn to predict

Detailed Breakdown:

Section 1: Next Deviation Prediction (Lines 97-99)
- shift(-1): Gets the NEXT reading's deviation values
- Creates targets for predicting future position

ML Logic: "Given current conditions, what will the deviation be in the next reading?"

Section 2: Required Corrections (Lines 101-102)
- required_hor_correction = next_position - current_position
- Calculates exactly how much steering correction is needed
- Positive value = need to steer right/up
- Negative value = need to steer left/down

ML Logic: "Given current conditions, how much should I adjust steering cylinders?"

Section 3: Improvement Metric (Line 105)
- deviation_improvement = current_total - next_total
- Positive value = getting better (deviation reducing)
- Negative value = getting worse (deviation increasing)

ML Logic: "Given current conditions, will my steering corrections improve alignment?"

Why This Design:
---------------
- Gives model 3 different prediction tasks to learn from
- Corrections are more actionable than raw predictions
- Improvement metric helps evaluate steering effectiveness

================================================================

6. ML DATA PREPARATION METHOD (Lines 111-152)
=============================================

Code Block:
-----------
def prepare_ml_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
    """Prepare features and targets for ML model"""
    
    # Select feature columns
    feature_cols = [
        # Current position
        'hor_dev_machine', 'vert_dev_machine', 'hor_dev_drill_head', 'vert_dev_drill_head',
        'yaw', 'pitch', 'roll', 'tunnel_length',
        
        # Steering controls
        'sc_cyl_01', 'sc_cyl_02', 'sc_cyl_03', 'sc_cyl_04', 'avg_cylinder_stroke', 'steering_cylinder_range',
        
        # Machine conditions
        'advance_speed', 'total_force', 'working_pressure', 'revolution_rpm', 'earth_pressure',
        'interjack_force', 'temperature',
        
        # Engineered features
        'total_deviation_machine', 'deviation_difference', 'pressure_ratio', 'force_per_advance',
        'steering_resistance', 'hor_dev_trend', 'vert_dev_trend', 'deviation_trend_magnitude',
        'advance_speed_ma', 'total_force_ma', 'earth_pressure_ma', 'progress_rate',
        
        # Previous steering actions
        'sc_cyl_01_change', 'sc_cyl_02_change', 'sc_cyl_03_change', 'sc_cyl_04_change'
    ]
    
    # Target columns (what we want to predict)
    target_cols = [
        'required_hor_correction',
        'required_vert_correction', 
        'deviation_improvement'
    ]
    
    # Remove rows with NaN values
    clean_df = df[feature_cols + target_cols].dropna()
    
    X = clean_df[feature_cols].values
    y = clean_df[target_cols].values
    
    self.feature_columns = feature_cols
    self.target_columns = target_cols
    
    return X, y

Purpose:
--------
Converts processed DataFrame into arrays suitable for ML algorithms

Detailed Breakdown:

Feature Selection (Lines 115-134):
34 input features organized by category:

Current Position (8 features):
- Machine and drill head deviations
- Orientation angles (yaw/pitch/roll)
- Current tunnel length

Steering Controls (6 features):
- All 4 cylinder positions
- Average stroke and range calculations

Machine Conditions (7 features):
- Speed, forces, pressures, temperature
- Real-time operational parameters

Engineered Features (8 features):
- Calculated metrics from feature engineering
- Trends, ratios, moving averages

Previous Actions (4 features):
- How much each cylinder moved recently
- Captures action-response patterns

Target Selection (Lines 136-141):
3 prediction outputs:
- Required horizontal correction
- Required vertical correction
- Expected deviation improvement

Data Cleaning (Lines 143-151):
clean_df = df[feature_cols + target_cols].dropna()
X = clean_df[feature_cols].values  # Input features
y = clean_df[target_cols].values   # Target outputs

Purpose:
- dropna(): Removes rows with missing values (NaN)
- .values: Converts DataFrame to NumPy arrays (required by scikit-learn)
- Stores column names for later use in predictions

ML Format:
- X: 2D array [samples, features] - input data
- y: 2D array [samples, targets] - output data

================================================================

7. MODEL TRAINING METHOD (Lines 154-192)
========================================

Code Block:
-----------
def train_model(self, X: np.ndarray, y: np.ndarray) -> Dict[str, Any]:
    """Train the steering prediction model"""
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Scale features
    X_train_scaled = self.scaler.fit_transform(X_train)
    X_test_scaled = self.scaler.transform(X_test)
    
    # Train Random Forest model (good for this type of engineering data)
    self.model = RandomForestRegressor(
        n_estimators=100,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )
    
    self.model.fit(X_train_scaled, y_train)
    
    # Evaluate model
    y_pred_train = self.model.predict(X_train_scaled)
    y_pred_test = self.model.predict(X_test_scaled)
    
    # Calculate metrics for each target
    results = {}
    for i, target in enumerate(self.target_columns):
        results[target] = {
            'train_r2': r2_score(y_train[:, i], y_pred_train[:, i]),
            'test_r2': r2_score(y_test[:, i], y_pred_test[:, i]),
            'train_mae': mean_absolute_error(y_train[:, i], y_pred_train[:, i]),
            'test_mae': mean_absolute_error(y_test[:, i], y_pred_test[:, i]),
            'train_rmse': np.sqrt(mean_squared_error(y_train[:, i], y_pred_train[:, i])),
            'test_rmse': np.sqrt(mean_squared_error(y_test[:, i], y_pred_test[:, i]))
        }
    
    return results

Purpose:
--------
Trains the ML model and evaluates its performance

Detailed Breakdown:

Data Splitting (Line 157):
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

- 80% training data: Used to teach the model patterns
- 20% testing data: Used to evaluate how well model generalizes
- random_state=42: Ensures reproducible splits

Feature Scaling (Lines 159-161):
X_train_scaled = self.scaler.fit_transform(X_train)
X_test_scaled = self.scaler.transform(X_test)

Purpose: Normalizes all features to similar ranges

Why Needed:
- tunnel_length might be 0-1000 meters
- temperature might be 15-25 degrees
- Without scaling, model would prioritize larger numbers

Process:
- fit_transform(): Learns scaling parameters from training data
- transform(): Applies same scaling to test data

Model Selection & Training (Lines 164-175):
self.model = RandomForestRegressor(
    n_estimators=100,      # 100 decision trees
    max_depth=15,          # Tree depth limit
    min_samples_split=5,   # Min samples to split node
    min_samples_leaf=2,    # Min samples in leaf node
    random_state=42,       # Reproducible results
    n_jobs=-1             # Use all CPU cores
)

Random Forest Algorithm Choice:
- Ensemble method: Combines 100 decision trees
- Good for engineering data: Handles non-linear relationships
- Robust: Less prone to overfitting than single decision tree
- Interpretable: Can analyze feature importance

Hyperparameter Explanation:
- n_estimators=100: More trees = better performance but slower
- max_depth=15: Prevents trees from memorizing training data
- min_samples_split=5: Prevents overly specific splits
- min_samples_leaf=2: Ensures meaningful leaf nodes

Model Evaluation (Lines 177-191):
# Calculate metrics for each target
for i, target in enumerate(self.target_columns):
    results[target] = {
        'train_r2': r2_score(y_train[:, i], y_pred_train[:, i]),
        'test_r2': r2_score(y_test[:, i], y_pred_test[:, i]),
        'train_mae': mean_absolute_error(y_train[:, i], y_pred_train[:, i]),
        'test_mae': mean_absolute_error(y_test[:, i], y_pred_test[:, i]),
        'train_rmse': np.sqrt(mean_squared_error(y_train[:, i], y_pred_train[:, i])),
        'test_rmse': np.sqrt(mean_squared_error(y_test[:, i], y_pred_test[:, i]))
    }

Evaluation Metrics Explained:

R² Score (Coefficient of Determination):
- Range: 0 to 1 (higher is better)
- 1.0 = perfect predictions
- 0.0 = predictions no better than average
- Measures percentage of variance explained

MAE (Mean Absolute Error):
- Average absolute difference between prediction and actual
- Units same as target (mm for corrections)
- Easy to interpret: "On average, predictions are off by X mm"

RMSE (Root Mean Square Error):
- Penalizes large errors more heavily than MAE
- Units same as target
- More sensitive to outliers

Train vs Test Comparison:
- Train metrics: Performance on data model has seen
- Test metrics: Performance on unseen data
- Large gap indicates overfitting

================================================================

8. PREDICTION AND UTILITY METHODS (Lines 194-268)
=================================================

Feature Importance Method (Lines 194-207):
------------------------------------------
Code:
def get_feature_importance(self) -> pd.DataFrame:
    """Get feature importance rankings"""
    if self.model is None:
        raise ValueError("Model not trained yet!")
        
    # Average importance across all targets
    avg_importance = np.mean(self.model.feature_importances_.reshape(-1, len(self.target_columns)), axis=1)
    
    importance_df = pd.DataFrame({
        'feature': self.feature_columns,
        'importance': avg_importance
    }).sort_values('importance', ascending=False)
    
    return importance_df

Purpose: Shows which input features are most important for predictions

Detailed Breakdown:
- self.model.feature_importances_: Random Forest calculates how much each feature contributes
- np.mean(): Averages importance across all 3 prediction targets
- Returns ranked list from most to least important

Engineering Value: Helps understand what factors matter most for steering decisions.

Prediction Method (Lines 209-225):
----------------------------------
Code:
def predict_steering_correction(self, current_data: Dict) -> Dict:
    """Predict required steering corrections for current conditions"""
    if self.model is None:
        raise ValueError("Model not trained yet!")
    
    # Convert input to feature vector (ensure same order as training)
    feature_vector = np.array([current_data.get(col, 0) for col in self.feature_columns]).reshape(1, -1)
    feature_vector_scaled = self.scaler.transform(feature_vector)
    
    # Make prediction
    prediction = self.model.predict(feature_vector_scaled)[0]
    
    return {
        'required_horizontal_correction': prediction[0],
        'required_vertical_correction': prediction[1], 
        'expected_deviation_improvement': prediction[2]
    }

Purpose: Makes predictions for new, real-time tunneling conditions

Detailed Breakdown:

Input Processing:
- current_data: Dictionary with current sensor readings
- current_data.get(col, 0): Gets value for each feature, defaults to 0 if missing
- reshape(1, -1): Converts to 2D array (required by scikit-learn)

Scaling:
- self.scaler.transform(): Applies same scaling used during training
- Critical: Must use identical preprocessing

Prediction:
- self.model.predict(): Gets model's prediction
- [0]: Extracts single prediction from array

Output:
- Returns human-readable dictionary with steering recommendations
- Positive/negative values indicate direction of correction needed

Visualization Method (Lines 227-268):
------------------------------------
Code:
def plot_results(self, df: pd.DataFrame):
    """Create visualization plots for steering analysis"""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. Deviation over distance
    axes[0,0].plot(df['tunnel_length'], df['total_deviation_machine'], label='Machine Deviation', alpha=0.7)
    axes[0,0].plot(df['tunnel_length'], df['total_deviation_drill_head'], label='Drill Head Deviation', alpha=0.7)
    # ... [plotting code continues]

Purpose: Creates 4 comprehensive analysis plots

Plot 1: Deviation vs Distance
- Shows how alignment changes along tunnel length
- Compares machine vs drill head positions
- Reveals problem areas and steering effectiveness

Plot 2: Steering Cylinder Usage
- Displays all 4 cylinder strokes over tunnel length
- Shows steering patterns and effort
- Identifies overused cylinders

Plot 3: Feature Importance Bar Chart
- Visual ranking of most important input features
- Helps understand model decision-making
- Guides future sensor prioritization

Plot 4: Deviation Trends
- Shows rate of change in horizontal/vertical deviation
- Reveals whether steering is improving or worsening
- Predictive indicator for future problems

================================================================

9. MAIN EXECUTION FLOW (Lines 271-331)
======================================

Code Block:
-----------
def main():
    """Example usage of the Steering Accuracy Predictor"""
    
    # Initialize predictor
    predictor = SteeringAccuracyPredictor()
    
    # Load and process data
    print("Loading AVN1200 drive data...")
    df = predictor.load_data('measure_protocol_original_.xls.csv')
    
    print("Engineering features...")
    df = predictor.engineer_features(df)
    df = predictor.create_targets(df)
    
    print(f"Data shape: {df.shape}")
    print(f"Drive length: {df['tunnel_length'].max():.1f}m")
    print(f"Total readings: {len(df)}")
    
    # Prepare ML data
    print("Preparing machine learning data...")
    X, y = predictor.prepare_ml_data(df)
    print(f"Features shape: {X.shape}")
    print(f"Targets shape: {y.shape}")
    
    # Train model
    print("Training steering prediction model...")
    results = predictor.train_model(X, y)
    
    # Print results
    print("\n=== MODEL PERFORMANCE ===")
    for target, metrics in results.items():
        print(f"\n{target.upper()}:")
        print(f"  Train R²: {metrics['train_r2']:.3f} | Test R²: {metrics['test_r2']:.3f}")
        print(f"  Train MAE: {metrics['train_mae']:.2f} | Test MAE: {metrics['test_mae']:.2f}")
        print(f"  Train RMSE: {metrics['train_rmse']:.2f} | Test RMSE: {metrics['test_rmse']:.2f}")
    
    # Feature importance
    print("\n=== TOP 10 IMPORTANT FEATURES ===")
    importance_df = predictor.get_feature_importance()
    for i, row in importance_df.head(10).iterrows():
        print(f"{row['feature']}: {row['importance']:.3f}")
    
    # Example prediction
    print("\n=== EXAMPLE STEERING PREDICTION ===")
    # Use current conditions from last reading
    current_conditions = df.iloc[-2][predictor.feature_columns].to_dict()
    prediction = predictor.predict_steering_correction(current_conditions)
    
    print(f"Required horizontal correction: {prediction['required_horizontal_correction']:.2f} mm")
    print(f"Required vertical correction: {prediction['required_vertical_correction']:.2f} mm") 
    print(f"Expected deviation improvement: {prediction['expected_deviation_improvement']:.2f} mm")
    
    # Create plots
    print("\nGenerating analysis plots...")
    predictor.plot_results(df)
    
    return predictor, df

if __name__ == "__main__":
    predictor, data = main()

Purpose:
--------
Demonstrates complete ML pipeline from data to predictions

Detailed Execution Flow:

Step 1: Initialization (Lines 274-275)
- Creates new SteeringAccuracyPredictor instance
- Sets up empty model, scaler, and column lists

Step 2: Data Loading & Processing (Lines 277-283)
- Loads CSV file with tunneling data
- Engineers 20+ new features from raw sensors
- Creates prediction targets (required corrections)
- Prints basic statistics about the dataset

Step 3: ML Data Preparation (Lines 285-290)
- Converts DataFrame to NumPy arrays
- Selects 34 input features and 3 output targets
- Cleans data by removing rows with missing values
- Prints array dimensions for verification

Step 4: Model Training (Lines 292-294)
- Splits data 80/20 for training/testing
- Scales features to standard ranges
- Trains Random Forest model
- Evaluates performance with multiple metrics

Step 5: Results Analysis (Lines 296-311)
Performance Metrics Display:
- Shows R², MAE, RMSE for each prediction target
- Compares training vs testing performance
- Identifies potential overfitting issues

Feature Importance Analysis:
- Lists top 10 most influential features
- Helps understand model decision-making
- Guides future feature engineering

Step 6: Real-Time Prediction Demo (Lines 313-321)
- Takes actual conditions from recent tunnel reading
- Makes steering correction predictions
- Demonstrates practical usage of trained model

Step 7: Visualization (Lines 323-325)
- Generates 4 comprehensive analysis plots
- Provides visual insights into tunneling performance
- Shows deviation patterns and steering effectiveness

Script Execution (Lines 330-331):
if __name__ == "__main__":
    predictor, data = main()

- Runs main() function when script is executed directly
- Returns trained model and processed data for interactive use

Overall Workflow Summary:
1. Raw Data → Processed Features → ML Arrays
2. Training → Evaluation → Validation
3. Feature Analysis → Predictions → Visualizations

This creates a complete end-to-end system for steering prediction in micro tunneling operations.

================================================================

10. SUMMARY & KEY LEARNING POINTS
=================================

Complete Code Understanding:
---------------------------
You now have a comprehensive understanding of every code block in the steering accuracy ML program. Here's how you can use this knowledge to write your own tunneling ML code:

Key Learning Points:
-------------------

1. Feature Engineering is Critical: The code creates 20+ new features from raw sensors - this is where the real ML magic happens

2. Multi-Target Prediction: Predicts 3 different outcomes simultaneously (horizontal, vertical corrections, improvement)

3. Time-Series Patterns: Uses rolling windows, trends, and lag features to capture temporal relationships

4. Engineering Domain Knowledge: Ratios like pressure_ratio and force_per_advance are more meaningful than raw values

5. Comprehensive Evaluation: Multiple metrics (R², MAE, RMSE) give full picture of model performance

For Your Own Implementation:
---------------------------
- Start with similar data loading and feature engineering patterns
- Focus on domain-specific engineered features for your tunneling application
- Use the same evaluation framework to validate your models
- Consider the prediction vs correction approach for actionable outputs

The code provides a solid template for any micro tunneling ML project - you can adapt the feature engineering and prediction targets to your specific use case.

================================================================

DOCUMENT END
============
This comprehensive explanation covers all aspects of the steering accuracy ML model.
Use this as a reference guide for understanding and implementing your own tunneling ML solutions.